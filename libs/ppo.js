/**
 * Minified by jsDelivr using Terser v5.17.1.
 * Original file: /npm/ppo-tfjs@0.0.2/ppo.js
 *
 * Do NOT use SRI with dynamically generated files! More information: https://www.jsdelivr.com/using-sri-with-dynamic-files
 */
if("object"==typeof module&&module.exports)var tf=require("@tensorflow/tfjs");function log(){console.log("[PPO]",...arguments)}class BaseCallback{constructor(){this.nCalls=0}_onStep(t){return!0}onStep(t){return this.nCalls+=1,this._onStep(t)}_onTrainingStart(t){}onTrainingStart(t){this._onTrainingStart(t)}_onTrainingEnd(t){}onTrainingEnd(t){this._onTrainingEnd(t)}_onRolloutStart(t){}onRolloutStart(t){this._onRolloutStart(t)}_onRolloutEnd(t){}onRolloutEnd(t){this._onRolloutEnd(t)}}class FunctionalCallback extends BaseCallback{constructor(t){super(),this.callback=t}_onStep(t){return!this.callback||this.callback(t)}}class DictCallback extends BaseCallback{constructor(t){super(),this.callback=t}_onStep(t){return!this.callback||!this.callback.onStep||this.callback.onStep(t)}_onTrainingStart(t){this.callback&&this.callback.onTrainingStart&&this.callback.onTrainingStart(t)}_onTrainingEnd(t){this.callback&&this.callback.onTrainingEnd&&this.callback.onTrainingEnd(t)}_onRolloutStart(t){this.callback&&this.callback.onRolloutStart&&this.callback.onRolloutStart(t)}_onRolloutEnd(t){this.callback&&this.callback.onRolloutEnd&&this.callback.onRolloutEnd(t)}}class Buffer{constructor(t){this.bufferConfig=Object.assign({},{gamma:.99,lam:.95},t),this.gamma=this.bufferConfig.gamma,this.lam=this.bufferConfig.lam,this.reset()}add(t,i,a,e,s){this.observationBuffer.push(t.slice(0)),this.actionBuffer.push(i),this.rewardBuffer.push(a),this.valueBuffer.push(e),this.logprobabilityBuffer.push(s),this.pointer+=1}discountedCumulativeSums(t,i){let a=[],e=0;return t.reverse().forEach((t=>{e=t+e*i,a.push(e)})),a.reverse()}finishTrajectory(t){const i=this.rewardBuffer.slice(this.trajectoryStartIndex,this.pointer).concat(t*this.gamma),a=this.valueBuffer.slice(this.trajectoryStartIndex,this.pointer).concat(t),e=i.slice(0,-1).map(((t,i)=>t-(a[i]-this.gamma*a[i+1])));this.advantageBuffer=this.advantageBuffer.concat(this.discountedCumulativeSums(e,this.gamma*this.lam)),this.returnBuffer=this.returnBuffer.concat(this.discountedCumulativeSums(i,this.gamma).slice(0,-1)),this.trajectoryStartIndex=this.pointer}get(){const[t,i]=tf.tidy((()=>[tf.mean(this.advantageBuffer).arraySync(),tf.moments(this.advantageBuffer).variance.sqrt().arraySync()]));return this.advantageBuffer=this.advantageBuffer.map((a=>(a-t)/i)),[this.observationBuffer,this.actionBuffer,this.advantageBuffer,this.returnBuffer,this.logprobabilityBuffer]}reset(){this.observationBuffer=[],this.actionBuffer=[],this.advantageBuffer=[],this.rewardBuffer=[],this.returnBuffer=[],this.valueBuffer=[],this.logprobabilityBuffer=[],this.trajectoryStartIndex=0,this.pointer=0}}class PPO{constructor(t,i){this.config=Object.assign({},{nSteps:512,nEpochs:10,policyLearningRate:.001,valueLearningRate:.001,clipRatio:.2,targetKL:.01,useSDE:!1,netArch:{pi:[32,32],vf:[32,32]},activation:"relu",verbose:0},i),Array.isArray(this.config.netArch)&&(this.config.netArch={pi:this.config.netArch,vf:this.config.netArch}),this.log=(...t)=>{this.config.verbose>0&&console.log("[PPO]",...t)},this.env=t,"Discrete"!=this.env.actionSpace.class||this.env.actionSpace.dtype?"Box"!=this.env.actionSpace.class||this.env.actionSpace.dtype||(this.env.actionSpace.dtype="float32"):this.env.actionSpace.dtype="int32",this.numTimesteps=0,this.lastObservation=null,this.buffer=new Buffer(i),this.actor=this.createActor(),this.critic=this.createCritic(),"Box"==this.env.actionSpace.class&&(this.logStd=tf.variable(tf.zeros([this.env.actionSpace.shape[0]]),!0,"logStd")),this.optPolicy=tf.train.adam(this.config.policyLearningRate),this.optValue=tf.train.adam(this.config.valueLearningRate)}createActor(){const t=tf.layers.input({shape:this.env.observationSpace.shape});let i=t;if(this.config.netArch.pi.forEach(((t,a)=>{i=tf.layers.dense({units:t,activation:this.config.activation}).apply(i)})),"Discrete"==this.env.actionSpace.class)i=tf.layers.dense({units:this.env.actionSpace.n}).apply(i);else{if("Box"!=this.env.actionSpace.class)throw new Error("Unknown action space class: "+this.env.actionSpace.class);i=tf.layers.dense({units:this.env.actionSpace.shape[0]}).apply(i)}return tf.model({inputs:t,outputs:i})}createCritic(){const t=tf.layers.input({shape:this.env.observationSpace.shape});let i=t;return this.config.netArch.vf.forEach(((t,a)=>{i=tf.layers.dense({units:t,activation:this.config.activation}).apply(i)})),i=tf.layers.dense({units:1,activation:"linear"}).apply(i),tf.model({inputs:t,outputs:i})}sampleAction(t){return tf.tidy((()=>{const i=tf.squeeze(this.actor.predict(t),0);let a;return"Discrete"==this.env.actionSpace.class?a=tf.squeeze(tf.multinomial(i,1),0):"Box"==this.env.actionSpace.class&&(a=tf.add(tf.mul(tf.randomStandardNormal([this.env.actionSpace.shape[0]]),tf.exp(this.logStd)),i)),[i,a]}))}logProbCategorical(t,i){return tf.tidy((()=>{const a=t.shape[t.shape.length-1],e=tf.logSoftmax(t);return tf.sum(tf.mul(tf.oneHot(i,a),e),e.shape.length-1)}))}logProbNormal(t,i,a){return tf.tidy((()=>{const e=tf.mul(-.5,tf.square(tf.sub(tf.div(a,i),tf.div(t,i)))),s=tf.add(tf.scalar(.5*Math.log(2*Math.PI)),tf.log(i));return tf.sum(tf.sub(e,s),e.shape.length-1)}))}logProb(t,i){return"Discrete"==this.env.actionSpace.class?this.logProbCategorical(t,i):"Box"==this.env.actionSpace.class?this.logProbNormal(t,tf.exp(this.logStd),i):void 0}predict(t,i=!1){return this.actor.predict(t)}trainPolicy(t,i,a,e){const s=()=>{const s=this.actor.predict(t),n=tf.sub(this.logProb(s,i),a),o=tf.exp(n),r=tf.where(tf.greater(e,0),tf.mul(tf.add(1,this.config.clipRatio),e),tf.mul(tf.sub(1,this.config.clipRatio),e));return tf.neg(tf.mean(tf.minimum(tf.mul(o,e),r)))};return tf.tidy((()=>{const{values:e,grads:n}=this.optPolicy.computeGradients(s);this.optPolicy.applyGradients(n);return tf.mean(tf.sub(a,this.logProb(this.actor.predict(t),i))).arraySync()}))}trainValue(t,i){const a=()=>{const a=this.critic.predict(t);return tf.losses.meanSquaredError(i,a)};tf.tidy((()=>{const{values:t,grads:i}=this.optValue.computeGradients(a);this.optValue.applyGradients(i)}))}_initCallback(t){return"function"==typeof t?void 0===t.prototype.constructor?new FunctionalCallback(t):t:"object"==typeof t?new DictCallback(t):new BaseCallback}async collectRollouts(t){null===this.lastObservation&&(this.lastObservation=this.env.reset()),this.buffer.reset(),t.onRolloutStart(this);let i=0,a=0,e=0;const s=[],n=[],o=[];for(let r=0;r<this.config.nSteps;r++){const[c,l,h,f]=tf.tidy((()=>{const t=tf.tensor([this.lastObservation]),[i,a]=this.sampleAction(t),e=this.critic.predict(t),s=this.logProb(i,a);return[i.arraySync(),a.arraySync(),e.arraySync()[0][0],s.arraySync()]}));s.push(c),n.push(l);let u=l;if("Box"==this.env.actionSpace.class){let t=this.env.actionSpace.high,i=this.env.actionSpace.low;"number"==typeof t&&"number"==typeof i&&(u=l.map((a=>Math.min(Math.max(a,i),t))))}o.push(u);const[p,d,g]=await this.env.step(u);if(i+=d,a+=1,this.numTimesteps+=1,t.onStep(this),this.buffer.add(this.lastObservation,l,d,h,f),this.lastObservation=p,g||r===this.config.nSteps-1){const t=g?0:tf.tidy((()=>this.critic.predict(tf.tensor([p])).arraySync()))[0][0];this.buffer.finishTrajectory(t),e+=1,this.lastObservation=this.env.reset()}}t.onRolloutEnd(this)}async train(t){const[i,a,e,s,n]=this.buffer.get(),[o,r,c,l,h]=tf.tidy((()=>[tf.tensor(i),tf.tensor(a,null,this.env.actionSpace.dtype),tf.tensor(e),tf.tensor(s).reshape([-1,1]),tf.tensor(n)]));for(let t=0;t<this.config.nEpochs;t++){if(this.trainPolicy(o,r,h,c)>1.5*this.config.targetKL)break}for(let t=0;t<this.config.nEpochs;t++)this.trainValue(o,l);tf.dispose([o,r,c,l,h])}async learn(t){let{totalTimesteps:i,logInterval:a,callback:e}=Object.assign({},{totalTimesteps:1e3,logInterval:1,callback:null},t);e=this._initCallback(e);let s=0;for(e.onTrainingStart(this);this.numTimesteps<i;)await this.collectRollouts(e),s+=1,a&&s%a==0&&log(`Timesteps: ${this.numTimesteps}`),this.train();e.onTrainingEnd(this)}}"object"==typeof module&&module.exports&&(module.exports=PPO);
//# sourceMappingURL=/sm/4e5eaca4bac2c8adec90ff121f0521c8e81c011c96c15a34391f3e0b86294ba9.map